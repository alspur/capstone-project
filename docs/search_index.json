[
["index.html", "Collaborative Analysis Development in Education Agencies About this book", " Collaborative Analysis Development in Education Agencies Alex Spurrier 2017-03-02 About this book This is a test. This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. "],
["introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction This will include an overview of the topics covered &amp; the motivation behind this book. "],
["analysis-development-in-education.html", "Chapter 2 Analysis development in education 2.1 What does it look like in education agencies? 2.2 Why should we care about the culture of data analysis?", " Chapter 2 Analysis development in education 2.1 What does it look like in education agencies? Now more than ever, the use of data is a critical component of strategic decision-making within organizations. As computing costs have dropped precipitously and the volume of raw data has grown exponentially, leaders in organizations are eager to leverage these trends to better inform their choices. The most significant barriers to a data-informed organization are no longer financial or technological. Instead, personnel and culture tend to be the largest obstacles for organizations looking to improve their use of data. Nowhere is this more true than in education. For years, educators and policy makers have been encouraged to embrace “data-driven decision-making,” but few education organizations have personnel that focus specifically on data analysis. Instead, it has become yet another skill we’ve asked educators to add to their already-overflowing professional responsibilities. Even in larger education organizations that are fortunate enough to have dedicated data analysts, such as state education agencies (SEA’s), cultural barriers often prevent them from operating as effectively as they could. Analysts are often program-specific staff working on their own. Collaboration among data analysts in SEA’s is frequently an exception, not the rule. 2.2 Why should we care about the culture of data analysis? Data analysis is difficult work. It requires an understanding of the field you’re studying, statistical knowledge, some programming ability, and most importantly, the ability to translate your results for non-analysts. At rstudio::conf() in January 2017, Hilary Parker gave a presentation that pinpoints some of the most critical challenges faced by data analysts. In her talk, she notes that “creating an analysis is a hard, error-ridden process that gets ‘yadda-yadda-ed’ away” because we’re reluctant to share our own workflows and/or limit another analyst’s “creativity.” These norms between analyst can not only limit their own professional growth, it inevitably leads to mistakes that go unnoticed because there’s only been one pair of eyes on a project. To address this problem, Parker recommends that we start to think about ourselves as “analysis developers” and borrow some concepts from programmers and engineers. Errors will happen. Parker notes that we can learn from operations engineers, particularly Sidney Dekker’s book, “Understanding Human Error.” The lesson of this book is to not blame a person for their errors and instead to look at the process they used. This helps to make the after-action review conversations less personal and more focused on solving the problem at hand. Reducing error is a big reason to care about developing a healthy, collaborative culture among “analysis developers,” but there are many other benefits to improving how these folks work. It can help improve the quality and depth of analysis as they start to learn from one another. A more collaborative environment can also improve the speed of analysis as analysis development moves from an ad-hoc approach to one that follows a more standardized routine. This will also help to improve institutional knowledge of the analysis development process, making it easier to integrate new staff and maintain stability after a personnel transition. Education agencies could develop more accurate, high-quality, and reproducible analyses, but it order to do so, they need to deliberately build a strong collaborative culture among their analysis developers. "],
["team-structure.html", "Chapter 3 Team structure 3.1 Your primary collaborator 3.2 E pluribus unum", " Chapter 3 Team structure 3.1 Your primary collaborator 3.2 E pluribus unum "],
["tools-of-the-trade.html", "Chapter 4 Tools of the trade 4.1 Data analysis software 4.2 Version control", " Chapter 4 Tools of the trade Before you start engaging in analysis development work within your agency, you’ll need to make sure you have the right tools to get the job done. There are two software tools every analyst should utilize: a scripting-based data analysis platform and a version control system. 4.1 Data analysis software The most commonly used data analysis software is Microsoft Excel. While nearly every analyst cuts their teeth crafting spreadsheets and pivot tables in this popular software, it’s not an ideal platform for professional analysis developers. Excel’s cell-based structure obscures the formulae that drive analysis work, making it hard for others (and often yourself) to understand what’s actually going on “under the hood.” Scripting-based data analysis languages are the cure for the common spreadsheet. They make the entire analysis process transparent by explicitly stating what actions will happen and the order in which they will be executed. I use and heartily recommend using R as your main platform for data analysis. It is free, open-source, and has a vibrant community of developers and practitioners working to improve the language. 4.2 Version control At some point, we’ve all worked on a project where we’ve saved multiple versions of a file. “Save as…” is a great tool for simple projects when you’re going from “v1” to “v2” to “final_draft,” but we can quickly push on the edges of this approach’s usefulness. If you want to go back to an earlier iteration of your work, it’s hard to know which version you’re looking for or what changed from “v3” to “v4.” If you’re working with multiple people, emailing documents back and forth, it’s amazing how quickly you can lose track of which “v3FINAL” document is the version you want to be looking at right now - is it the one Jane sent yesterday or is the one Johnny sent today? Version control systems help to alleviate these problems. Instead of requiring you to save multiple versions of one file, version control software allows you to have one file, but track all of the changes made since its inception. The most commonly used version control system is Git, which can be paired with the GitHub service to keep a copy of your documents and the changes you’ve made to them in the cloud. Link to Happy Git and GitHub for the useR "],
["communication-is-key.html", "Chapter 5 Communication is key 5.1 Meet regularly 5.2 Establish norms 5.3 Review code", " Chapter 5 Communication is key 5.1 Meet regularly 5.2 Establish norms 5.3 Review code "],
["establish-systems.html", "Chapter 6 Establish systems 6.1 Common analysis format 6.2 Style guide 6.3 Procedural checklists", " Chapter 6 Establish systems 6.1 Common analysis format 6.2 Style guide 6.3 Procedural checklists "],
["collaborate-on-analysis-development.html", "Chapter 7 Collaborate on analysis development 7.1 Working together on Github 7.2 Code review", " Chapter 7 Collaborate on analysis development 7.1 Working together on Github 7.2 Code review "],
["identify-pain-points.html", "Chapter 8 Identify pain points 8.1 Figure out common problems 8.2 Has anyone already solved this problem? 8.3 Develop internal solutions", " Chapter 8 Identify pain points 8.1 Figure out common problems 8.2 Has anyone already solved this problem? 8.3 Develop internal solutions "],
["share-beyond-your-walls.html", "Chapter 9 Share beyond your walls", " Chapter 9 Share beyond your walls "],
["conclusion.html", "Chapter 10 Conclusion", " Chapter 10 Conclusion "]
]
