[
["index.html", "Collaborative Analysis Development in Education Agencies About this book", " Collaborative Analysis Development in Education Agencies Alex Spurrier 2017-08-30 About this book Producing data analysis products is challenging work, particularly within education agencies. This book details the tools and systems that education agency analysts can adopt to move their work from isolated analysis to collaborative analysis development. This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. "],
["introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction This will include an overview of the topics covered &amp; the motivation behind this book. "],
["analysis-development-in-education.html", "Chapter 2 Analysis development in education 2.1 What does it look like in education agencies? 2.2 Who are we talking about? 2.3 Why should we care about the culture of data analysis?", " Chapter 2 Analysis development in education 2.1 What does it look like in education agencies? Now more than ever, the use of data is a critical component of decision-making within organizations. As computing costs continue their precipitous decline and the volume of raw data grows exponentially, leaders in education agencies are eager to leverage these trends to better inform their choices. The most significant barriers to a data-informed education agency are no longer financial or technological. Instead, personnel and culture tend to be the largest obstacles for organizations looking to improve their use of data. For years, educators and policy makers have been encouraged to embrace “data-driven decision-making,” but few education organizations have personnel that focus specifically on data analysis. Instead, it has become yet another skill we’ve asked educators to add to their already-overflowing professional responsibilities. Larger education organizations are fortunate enough to have dedicated data analysts, particularly state education agencies (SEA’s), but cultural barriers often prevent them from operating as effectively as they could. Analysts are often program-specific staff working in isolation. Collaboration among data analysts in SEA’s is frequently an exception, not the rule. Education agencies of different sizes and missions face different data problems. School systems collect and process a variety of information generated by their students and employees, then report the results to a wide range of audiences.Their data could be coming from millions of students and thousands of educators in a large state to a hundred students and a dozen teachers in a start-up charter school, but they both have the same goal in doing so: improving the outcomes of their students. Non-profit organizations focusing on education policy face different challenges. Since they aren’t directly generating much data on student, school, or educator performance, they typically rely on publicly-available data sources. These organizations then use that information to support programs and policies that will help more students succeed. Regardless of an education agency’s size or mission, they all have a similar job. They collect funding, then allocate it to programs and/or staff to ultimately improve education for kids. In order to inform their efforts, they collect data to guide their decision-making. The key question these agencies must continually ask themselves: are we collecting the right data and analyzing it appropriately to inform our work? If the answer is a strong “yes” with significant supporting evidence, well done! If not, this book can help. 2.2 Who are we talking about? Education agency employees vary in their interactions with data. Some directly manage student information systems (pretty data-heavy work) while others mostly consume data from reports and briefings. Is there a clear point on that spectrum which clearly delineates someone as an “analyst?” Probably not, but it’s helpful to set a working definition for our purposes: An analyst in an education agency is anyone whose primary work is focused on the collection, transformation, and communication of data. Under this definition, and analyst is less defined by the tools and techniques they use than the amount of time they spend working with data. Some analysts are spreadsheet warriors while others write code. Some analysts will only need the SUM() and AVERAGE() functions in Excel while others will apply sophisticated machine learning techniques. At the end of the day, anyone who spends most of their workday collecting, transforming, and sharing data is an analyst. 2.3 Why should we care about the culture of data analysis? Data analysis is difficult work. It requires an understanding of the field you’re studying, statistical knowledge, some programming ability, and most importantly, the ability to translate your results for non-analysts. At rstudio::conf() in January 2017, Hilary Parker gave a presentation that pinpoints some of the most critical challenges faced by data analysts. In her talk, she notes that “creating an analysis is a hard, error-ridden process that gets ‘yadda-yadda-ed’ away” because we’re reluctant to share our own workflows and/or limit another analyst’s “creativity.” These norms between analyst can not only limit their own professional growth, it inevitably leads to mistakes that go unnoticed because there’s only been one pair of eyes on a project. To address this problem, Parker recommends that we start to think about ourselves as “analysis developers” and borrow some concepts from programmers and engineers. Errors will happen. Parker notes that we can learn from operations engineers, particularly Sidney Dekker’s book, “Understanding Human Error.” The lesson of this book is to not blame a person for their errors and instead to look at the process they used. This helps to make the after-action review conversations less personal and more focused on solving the problem at hand. Reducing error is a big reason to care about developing a healthy, collaborative culture among “analysis developers,” but there are many other benefits to improving how these folks work. It can help improve the quality and depth of analysis as they start to learn from one another. A more collaborative environment can also improve the speed of analysis as analysis development moves from an ad-hoc approach to one that follows a more standardized routine. This will also help to improve institutional knowledge of the analysis development process, making it easier to integrate new staff and maintain stability after a personnel transition. Education agencies could develop more accurate, high-quality, and reproducible analyses, but it order to do so, they need to deliberately build a strong collaborative culture among their analysis developers. "],
["team-structure.html", "Chapter 3 Team structure 3.1 Your primary collaborator 3.2 E pluribus unum", " Chapter 3 Team structure 3.1 Your primary collaborator No man is an island, and analysis developers are no different. Even if you are working as the lone analysis developer in your agency, it doesn’t mean you can neglect the structures a team needs to be successful. As Hadley Wickham notes in his Expressing yourself with R talk: “Every project you work on is fundamentally collaborative. Even if you’re not working with any other person, you are always working with future you. And you really don’t want to be in a situation where future you has no idea what past you was thinking, because past you will not respond to any emails.” The rest of this book assumes that you have embraced this idea. No matter the size of your team, from 1 to n, it is critical that you think about, test, and improve the systems you use to collaborate with others. 3.2 E pluribus unum Teams of analysis developers don’t form on their own - it takes leadership to build, grow, and maintain. The work can be challenging, as many prospective team members may come from different backgrounds, use different software packages, or tackle analysis via idiosyncratic (at sometimes inscrutable) methods. Yet at the same time, the heterogeneity of your team is also an asset. The differing perspectives and strengths of your team’s members will allow you to survey problems from different angles and help mitigate the danger of group-think. The leader of a analysis development team needs to do more than run meetings and assign work. They may help provide support on implementing particular methodologies, perform final code reviews, and approve analysis before it is shipped outside the team. But the most critical job they have is to ensure a healthy team culture. Building a strong team culture is hard. It relies on mutual trust, humility, and honesty - virtues that aren’t always easy to embody. But it can be done. As you start to think intentionally about your team’s culture, this sequence is a helpful staring point: Understand what your team culture is like right now. Define what direction your culture needs to move. Identify the behaviors/routines your team will implement to get there. Implement the selected behaviors/routines. Repeat. This process is a variant of the Observe-Orient-Decide-Act (OODA) loop a strategic decision-making processed developed by a fighter pilot. While building a team of analysis developer’s isn’t quite as intense as a dogfight, this process of intentional observation, decision-making, and action is an extremely helpful way to start improving your team’s culture at any stage of development. Developing a strong team culture is not a goal - it’s a continual process. This variation of the OODA loop supports thoughtful observation, adaptation, and action. If your team is just starting to meet and is very heterogeneous, you won’t be able to get everybody working on the same software and using the same processes overnight. It will require intentional, incremental, and iterative change over time. "],
["tools-of-the-trade.html", "Chapter 4 Tools of the trade 4.1 Data analysis software 4.2 Version control", " Chapter 4 Tools of the trade Before you start engaging in analysis development work within your agency, you’ll need to make sure you have the right tools to get the job done. There are two software tools every analyst should utilize: a script-based data analysis software platform and a version control system. 4.1 Data analysis software The most commonly used data analysis software is Microsoft Excel. While nearly every analyst cuts their teeth crafting spreadsheets and pivot tables in this popular software, it’s not an ideal platform for professional analysis developers. Excel’s cell-based structure obscures the formulas that drive analysis work, making it hard for others (and often yourself) to understand what’s actually going on “under the hood.” Scripting-based data analysis languages are the cure for the common spreadsheet. They make the entire analysis process transparent by explicitly stating what actions will happen and the order in which they will be executed. This helps to not only clarify your own analytic approach, it also makes it much easier to catch bugs in your analyses. 4.1.1 The case for R There are many software packages that are well-suited for data analysis, but I use and heartily recommend using R as your main platform for data analysis. It is free (a very important feature to analysis developers working in the public/non-profit sectors), open-source, and has a vibrant community of developers and practitioners working to improve the language. One of the best features of the R language is the comprehensive and diverse collection of packages available on CRAN (the Comprehensive R Archive Network). Packages are the way users in the R community share the tools they create - they contain some combination of R code, documentation, and data. Some of the most popular packages allow users to easily perform statistical operations, create plots, and manipulate their data. R users are also able to take advantage of one of the best integrated development environments (IDE’s), RStudio. This freely available software allows users to interact with an R console, write scripts, view plots, and more through a graphical user interface (GUI). RStudio also has built-in functionality to work with some of the most popular version control systems, including Git and GitHub (more on that later). Perhaps the greatest advantage R has over other data analysis software packages is its community. Package development and support is a big part of this, but the R community is also very active in supporting the growth and development of new R users. There are many free ways to get started learning R, from courses on Coursera to online books. If you’re looking for a place to get started, I recommend R for Data Science. 4.2 Version control At some point, we’ve all worked on a project where we’ve saved multiple versions of a file. “Save as…” is a great tool for simple projects when you’re going from “v1” to “v2” to “final_draft,” but we can quickly push on the edges of this approach’s usefulness. If you want to go back to an earlier iteration of your work, it’s hard to know which version you’re looking for or what changed from “v3” to “v4.” If you’re working with multiple people, emailing documents back and forth, it’s amazing how quickly you can lose track of which “v3FINAL” document is the version you want to be looking at right now - is it the one Jane sent yesterday or is the one Johnny sent today? Version control systems help to alleviate these problems. Instead of requiring you to save multiple versions of one file, version control software allows you to have one file, but track all of the changes made since its inception. The most commonly used version control system is Git, which can be paired with the GitHub service to keep a copy of your documents and the changes you’ve made to them in the cloud. As mentioned above, RStudio integrates well with these services. To learn more about getting started with Git, GitHub, and RStudio, check out Happy Git and GitHub for the useR "],
["communication-is-key.html", "Chapter 5 Communication is key 5.1 Meet regularly 5.2 Establish norms", " Chapter 5 Communication is key Building a team of analysis developers starts with a foundation of honest, humble, and frequent communication. Most analysis developers in education agencies start their careers in isolation, left to their own devices to work with the data for a particular program area or set of schools. Breaking out of that isolation to collaborate with others is difficult, but it all starts with developing strong and supportive systems of communication. 5.1 Meet regularly It may sound obvious, but the first step to establishing good communication as a team of analysis developers is to start meeting and talking on a regular basis. As busy as things can get in our agencies, it is worth carving out an hour of your week to get together and talk about your current projects, challenges you’re facing, and successes you’re realizing. If an hour seems like too much, start with a half hour, but start this habit as soon as you can. Meeting regularly with your team of analysis developers has several benefits. It provides your teammates with the opportunity to step back from their day-to-day work and share their perspective. If one person is struggling with a particular part of a project, another teammate may have tackled a similar challenge earlier in the year and be able to share how they were able to overcome it. These serendipitous moments of collaboration and informal professional development are much more likely to occur if you establish a forum for these conversations to occur. More importantly, meeting regularly helps to establish stronger informal relationships between team members. Not every item on the agenda needs to be strictly work-related, you can also take time to share part of your non-office life. This is a form of team-building that is often overlooked, but it shouldn’t be ignored. Even seemingly-mundane small-talk about what you have planned for the weekend can help build trust and rapport between teammates, making the challenge of forming a high-functioning team much less daunting. 5.2 Establish norms As you start to meet regularly with your team, you will also want to take the time to establish and model healthy norms to support open and honest communication. Sharing your work can be a nerve-racking proposition, exponentially so if you’re trying a new approach or learning a new software language. Setting expectations on the front-end of those conversations will reduce that tension and lead to more productive feedback. To start, make it clear that any feedback on an analysis project is strictly about the process and not about the person. Hilary Parker covers this topic in a talk she gave at the 2017 rstudio::conf(), Opinionated Analysis Development. She discusses the “blameless postmortem” process used during her time at Etsy, in which any errors were discussed by evaluating the process that led to the error, not the person responsible. Mistakes will happen in our work - an approach to resolving them that focuses on improving process over assigning blame to a person will ultimately lead to more productive and less emotional conversations. These conversations about the process of data analysis should be grounded in a sense of humility. While some may be more comfortable and confident in their expertise, nobody has the perfect answer to every problem. As we become experts, it’s important to remember how it felt to be a novice. Any feedback we provide to others should always be done in a spirit that recognizes we tackle difficult problems and are all learning to get better with each analysis we craft. It is also important that while we provide feedback on processes with a sense of humility, it must also be delivered as honestly as possible. Pointing out errors in a particular analytic approach or offer more optimal workflow is good - that’s how we learn and grow. But we must always take caution to make sure that this honest feedback is always focused on the process and not the person. "],
["establish-systems.html", "Chapter 6 Establish systems 6.1 Common analysis format 6.2 Style guide 6.3 Procedural checklists", " Chapter 6 Establish systems Once your team establishes a strong communication system, it’s time to start building systems that will support effective collaboration. Meeting regularly and establishing norms set the foundation for you to have an open and constructive dialogue about approaches and processes that can give your team more consistency and standardization in the development of analysis products. This isn’t to say that you should strive to have every analysis developer’s work look identical - if that were the case, you could simply write a script to automate it. Moving your team towards more and not total consistency and standardization means that when you have opportunities to provide feedback on work, the barriers to understanding are minimized. Seemingly minor roadblocks to understanding what a script is doing, like its organization or how variables are named, each serve as a cognitive tax. Establishing good systems will help you limit the level of cognitive taxation required to read a teammate’s code, leaving more capacity to engage in the work of analysis development. 6.1 Common analysis format One of the first tasks your team should tackle is developing a common format for analysis. Developing a common format for analysis can help improve understanding of scripts even if they are coded in different languages. A helpful starting point for this conversation is a diagram found in chapter 2 of R for Data Science: worflow_diagram Our team developed our standard analysis template based on this workflow. We start by first importing all packages and raw data that we will need for the analysis. The second section of our code gets the data in a “tidy” format - variables get converted to the proper type, missing variables are addressed, and tables are reshaped to ensure that each column is a variable and each row is a single observation (more on tidy data can be found in R for Data Science chapter 12.2). Once we have tidy data, we then move on to the heart of our analysis work, which always involves some combination of data transformation, modeling, or visualization. Once all of those steps are completed, we then start to develop how we will communicate the results of our analysis. Here is the exact code we use in our template analysis script, which is available on GitHub: # title of analysis # # date started (yyyy-mm-dd) # lead analysis developer # # notes re: purpose of project # load --------------------------- # load packages # load raw data # clean --------------------------- # prepare data in a tidy format # analyze ------------------------- # transform, model, and/or visualize data # communicate --------------------- # produce objects (tables, charts, etc) for communcating results If all of your team starts analysis projects with this template or one that best suits your needs, it reduces the barriers ahead of each team member understanding what an analysis script is doing. You will be able to quickly isolate potential errors or identify creative approaches to replicate in other analyses. 6.2 Style guide Code style is a constant topic of debate among software developers. Naming conventions, commenting practices, white space, and of course, tabs vs. spaces. There are many pre-defined style guides out there for statistical programming languages. As citizens of the tidyverse, our team adheres to the Tidyverse R Style Guide. That may be the right choice for your team or it might not. The point is that you and your teammates need to make a choice and stick to it. It will make reviewing code much, much easier. 6.3 Procedural checklists Apart from your analysis structure and style, your team should also define the procedure for tasks you’ll do on a routine or semi-routine schedule. Once you’ve defined these procedures, be sure to document them in a series of checklists. Several of [o]ur team’s checklists are available on GitHub](https://github.com/alspur/analysis_dev_templates/tree/master/checklists). Why checklists? If it works for airline pilots and surgeons, it can work for analysis developers. Atul Gawande’s book, The Checklist Manifesto, explains the value of checklists to highly skilled workers. Professionals of all varieties - programmers, doctors, teachers, pilots, etc. - perform cognitively demanding tasks on regular basis in high-stakes settings. They apply the skills they’ve honed through training, their understanding of their field, and their general experience to execute complex tasks. But no matter how competent or prepared these professionals are, they still make mistakes. Gawande writes: “In a complex environment, experts are up against two main difficulties. The first is the fallibility of human memory and attention, especially when it comes to mundane, routine matters that are easily overlooked under the strain of more pressing events.” … “A further difficulty, just as insidious, is that people can lull themselves into skipping steps even when they remember them. In complex processes, after all, certain steps don’t always matter. Perhaps the elevator controls on airplanes are usually unlocked and a check is pointless most of the time. Perhaps measuring all four vital signs uncovers a worrisome issue in only one out of fifty patients. “This has never been a problem before,” people say. Until one day it is.” There’s nothing wrong with confidence in your ability to practice your profession, but it does breed a degree hubris that even when seemingly benign, can lead to significant errors. Gwande provides several examples of this in the medical field, where skipping seemingly obvious steps can lead to someone having their right knee opened up even if they’re in for an ACL repair on their left knee. The concept of minimizing mistakes in routine processes is also applicable to analysis development. Each analysis project involves follows the broad format of importing, cleaning, transforming, and reporting data. If small steps along the way aren’t double-checked, a tiny error can lead to significant problems with the results. Gwande stresses that using checklists to minimize error isn’t meant to dumb down the work of professionals. Instead, he argues: “It is common to misconceive how checklists function in complex lines of work. They are not comprehensive how-to guides, whether for building a skyscraper or getting a plane out of trouble. They are quick and simple tools aimed to buttress the skills of expert professionals.” … “You want people to make sure to get the stupid stuff right. Yet you also want to leave room for craft and judgment and the ability to respond to unexpected difficulties that arise along the way” Checklists must strike an important balance. They need to cover enough critical points in a process to minimize the “stupid stuff” that could happen, but they also need the flexibility and brevity to be useful in a real-world setting. Gwande explains the difference between a good checklist and a bad one: “Bad checklists are vague and imprecise. They are too long; they are hard to use; they are impractical. They are made by desk jockeys with no awareness of the situations in which they are to be deployed. They treat the people using the tools as dumb and try to spell out every single step. They turn people’s brains off rather than turn them on. Good checklists, on the other hand, are precise. They are efficient, to the point, and easy to use even in the most difficult situations. They do not try to spell out everything—a checklist cannot fly a plane. Instead, they provide reminders of only the most critical and important steps—the ones that even the highly skilled professionals using them could miss. Good checklists are, above all, practical.” Work with your team to develop good checklists. The most valuable checklists you’ll develop are the ones you actually end up using. Start identifying the critical steps in your work, write them down, and iterate your checklists to help your team minimize error and ensure consistent quality. "],
["collaborate-on-analysis-development.html", "Chapter 7 Collaborate on analysis development 7.1 Code reviews 7.2 Collaborative Coding", " Chapter 7 Collaborate on analysis development Once your team has started meeting regularly, established norms, and built some common analysis templates and/or style guides, you’ll be ready to take the next step in collaboration: actually working on code as a team. This is much easier if you are all working in the same programming language (or languages). 7.1 Code reviews The first level of coding collaboration your team should try is a code review - a process by which one developer shares their code with other developers to get constructive feedback. In the software development world, code reviews help teams minimize bugs and critical vulnerabilities. Analysis developers can realize similar benefits by conducing code reviews with their teams. Every project will have buggy code at some point. Many times, the lead developer will be able to catch those bugs as they are coding their analysis, but sometimes an error will slip through their personal review process. If you’re staring at the same lines of code for days, you may miss something that could be obvious to someone looking at the same code with fresh eyes. Code reviews are incredibly helpful to spot and correct those kinds of mistakes. A code review is also a helpful process to help an analysis developer check their work for methodological blind spots. Walking through your code with your teammates can help ensure you’re all on the same page with the particular choices you’ve made regarding cleaning, transforming, modeling, and visualizing your data. If there are differing opinions on particular choices, a code review is a great forum to resolve those differences. All of this sounds great - just share your code with your teammates and you’ll squash bugs and resolve any methodological vulnerabilities - but it can also go very poorly if you haven’t established a strong level of trust and open communication on your team. Sharing your code for the first time is a nerve-racking experience. Make sure that when your team tries a code review for the first time, you set some explicit norms for that conversation: Decide at the beginning of the conversation how the presenter would like to take questions and comments. Wait until the end? Jump in anytime? Since it’s their code, let the presenter decide what’s more comfortable for them. If you’re giving feedback, remember to focus your comments and questions on the process and not the person. If you spot an error, don’t lead with saying “You forgot to include variable x in your group_by() call on line 53.” Instead, explain the issue you’re seeing and why you might suggest a different approach. This approach will help all of your teammates to understand the issue and the recommended solution, turning a moment of potential embarrassment into a learning opportunity for the whole team. Code reviews, when done well, can be a great way to improve code quality and further develop your team’s coding skills. Just make sure you’ve done enough to build your team culture first - this will help ensure that it’s a positive and productive experience. 7.2 Collaborative Coding Direct collaboration on analysis project code is incrediblly powerful. Instead of waiting for an analysis project to make it to a code review, collaborative coding makes the development and review of code an organically iterative process. Collaboartive coding can be performed in-person by pair programming: “Pair programming is an agile software development technique in which two programmers work together at one workstation. One, the driver, writes code while the other, the observer or navigator, reviews each line of code as it is typed in. The two programmers switch roles frequently. “While reviewing, the observer also considers the”strategic&quot; direction of the work, coming up with ideas for improvements and likely future problems to address. This frees the driver to focus all of their attention on the “tactical” aspects of completing the current task, using the observer as a safety net and guide.&quot; Pair programming is a useful process for analysis developers to consider. It essentially creates a live code review process as the code is being written. This may work well in some education agencies, but others may find it difficult, particularly if a team works in an open-plan office (noise barriers) or in separate buildings (geographic barriers). However, developers can overcome barriers generated by office design through the use of Git and GitHub. Git version control software and the web service GitHub are amazing tools. The learning curve can be a little steep since it involves some interaction with the command line, but there are resources that make it much easier to adopt these tools. In particular, Jenny Bryan’s Happy Git and GitHub for the UseR is a great introduction to these tools for R users and how to use them within RStudio. Once your team has some working knowledge of how to use Git and GitHub, it’s pretty easy to start collaborating on analysis projects. If one analysis developer starts a GitHub “repo” for a project, another developer can “fork” their work, make changes and/or additions, then submit a “pull request” to merge their work into the original repo. The beauty of collaborating on code with GitHub is that it allows your team to contribute to projects asynchronously. This enables analysis developers to work together even if their locations or schedules make pair programming or in-person code reviews diffiucult. It also makes it easy for a team to have a shared collection of commonly-used code, which can further contribute to the standardization, reliablity, and speed of analysis development. "],
["identify-pain-points.html", "Chapter 8 Identify pain points 8.1 Has anyone already solved this problem? 8.2 Develop internal solutions 8.3 Case study: Kentucky’s School Report Card data", " Chapter 8 Identify pain points As your team works, you will inevitably run into roadblocks when executing analysis projects. You may even notice that some of these obstacles are recurring problems. While it may seem like an inconvenience, your team can actually turn these pain points into an opportunity for improvement. In the book R for Data Science, Hadley Wickham recommends that if you’ve done a copy-and-paste of the same code more than two times, you should write a function to simplify that action. Taken a step further, we should also recognize that if we’re repeating lines of code or functions in multiple projects, those actions ought to be converted into a more reusable set of code for your team. These common tools could be as simple as a script to help format ggplot2 graphics or it could be as complex as a full-blown R package. No matter the form, applying common code that can address your team’s pain points will help improve your team’s programming skill as well as improve the efficiency of your team’s workflow. 8.1 Has anyone already solved this problem? Once your team has identified a common pain point in your analysis development workflow, the first step you should take it to determine if anyone has a ready-to use solution. From new users to master developers, every level of programmer at some point will turn to a search engine to answer a programming question. Taking a few minutes to search a programming question on Google or Stack Overflow is often one of the best uses of an analysis developer’s time - five minutes finding an answer to a question is vastly preferred to spending an hour or three trying to figure it out the answer in isolation. 8.2 Develop internal solutions Sometimes, your team won’t be able to find a ready-made solution to the pain points you encounter. It’s at this point that your team can start exploring functional programming or package development as a way to improve your workflow. Developing a custom solution to a pain point should start with creating a function to solve the problem. If the problem is more complex, it might require writing several functions. How to approach this is beyond the scope of this book, but R for Data Science and Advanced R Programming are great resources to help you build functions to address your team’s pain points. If the pain points your team encounters are common across multiple projects and you work in R, you may want to consider developing an R package for your team. A package is a way to share R code, data, and documentation with other R users. If your team needs to format plots according to your organization’s style guide, your R package could include a function that applies the proper theme and color palette to your ggplot2 graphics. If you frequently perform a certain cleaning operation on your data, the package could include those functions. To get started building your own R packages, Hadley Wickham’s R Packages book is the best place to start. 8.3 Case study: Kentucky’s School Report Card data Working at the Kentucky Department of Education (KDE), many of the small analysis projects I worked on with my team were focused on a question that could be answered by looking at data from Kentucky’s School Report Card (SRC) website. The SRC includes demographic, academic, financial, and staffing data for every public school in the Commonwealth, so it typically the starting point for most questions about students, schools, or districts. While the SRC has a great deal of useful information, it isn’t accessible in a format that is friendly to data analysis. Different categories of data are housed in different Excel files, and even within one category, data from different school years are split into one Excel file per year. This means that for any comparison of school performance across multiple years, an analyst must download multiple Excel files, then clean and join them. If an analyst wants to include demographic data along with school performance data, the number of Excel files to download, clean, and join doubles. During my first year working at KDE, I went through the routine of downloading, cleaning, and joining SRC Excel files dozens of times. I eventually realized that I could save hours per week by taking the SRC data I used most frequently, cleaning it, and storing it in an R package. After a few weeks of working through Hadley Wickham’s R Packages book, kysrc was born. Over the course of a year, I continued to improve the kysrc package, adding new data sets and vignettes to make it even more useful. As my team of analysts grew from one to three, I helped our new hires save hours that would have been spent cleaning data. The barriers to analyzing SRC data are now lower and as a result, our team is vastly more efficient. "],
["share-beyond-your-walls.html", "Chapter 9 Share beyond your walls 9.1 Internal sharing 9.2 External sharing", " Chapter 9 Share beyond your walls Working well within your team is great, but you should also start to share your work with others. This can help generate new research ideas, identify ways to improve your work, or generate new partnerships. 9.1 Internal sharing Other teams Leadership 9.2 External sharing Blog Twitter Stack Overflow "],
["conclusion.html", "Chapter 10 Conclusion", " Chapter 10 Conclusion "]
]
