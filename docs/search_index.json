[
["index.html", "Collaborative Analysis Development in Education Agencies About this book", " Collaborative Analysis Development in Education Agencies Alex Spurrier 2017-07-11 About this book Producing data analysis products is challenging work, particuarly within education agencies. This book details the tools and systems that educaiton agency analysts can adopt to move their work from isolated analysis to collaborative analysis development. This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. "],
["introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction This will include an overview of the topics covered &amp; the motivation behind this book. "],
["analysis-development-in-education.html", "Chapter 2 Analysis development in education 2.1 What does it look like in education agencies? 2.2 Who are we talking about? 2.3 Why should we care about the culture of data analysis?", " Chapter 2 Analysis development in education 2.1 What does it look like in education agencies? Now more than ever, the use of data is a critical component of decision-making within organizations. As computing costs continue their precipitous decline and the volume of raw data grows exponentially, leaders in education agencies are eager to leverage these trends to better inform their choices. The most significant barriers to a data-informed education agecy are no longer financial or technological. Instead, personnel and culture tend to be the largest obstacles for organizations looking to improve their use of data. For years, educators and policy makers have been encouraged to embrace “data-driven decision-making,” but few education organizations have personnel that focus specifically on data analysis. Instead, it has become yet another skill we’ve asked educators to add to their already-overflowing professional responsibilities. Larger education organizations are fortunate enough to have dedicated data analysts, particuarly state education agencies (SEA’s), but cultural barriers often prevent them from operating as effectively as they could. Analysts are often program-specific staff working in isolation. Collaboration among data analysts in SEA’s is frequently an exception, not the rule. Education agencies of different sizes and missions face different data problems. School systems collect and process a variety of information generated by their students and employees, then report the results to a wide range of audiences.Their data could be coming from millions of students and thousands of educators in a large state to a hundred students and a dozen teachers in a startup charter school, but they both have the same goal in doing so: improving the outcomes of their students. Non-profit organizations focusing on education policy face different challenges. Since they aren’t directly generating much data on student, school, or educator performance, they typically rely on publicly-available data sources. These organizations then use that imforation to support programs and policies that will help more students succeed. Regardless of an education agency’s size or mission, they all have a similar job. They collect funding, then allocate it to programs and/or staff to ultimately improve edcuation for kids. In order to inform their efforts, they collect data to guide their decision-making. The key question these agencies must continuially ask themselves: are we collecting the right data and analyzing it appropraitely to inform our work? If the answer is a strong “yes” with significant supporting evidence, well done! If not, this book can help. 2.2 Who are we talking about? Education agency employees vary in their iteraction with data. Some directly manage student information systems (pretty data-heavy work) while others mostly consume data from reports and briefings. Is there a clear point on that spectrum which clearly deliniates someone as an “analyst?” Probably not, but it’s helpful to set a working definition for our purposes: An analyst in an education agency is anyone whose primary work is focused on the collection, transformation, and communication of data. Under this definition, and analyst is less defined by the tools and techniques they use than the amount of time they spend working with data. Some analysts are spreadsheet warriors while others write code. Some analysts will only need the SUM() and AVERAGE() functions in Excel while others will apply sophisicated machine learning techniques. At the end of the day, anyone who spends most of their workday collecting, transforming, and sharing data is an analyst. 2.3 Why should we care about the culture of data analysis? Data analysis is difficult work. It requires an understanding of the field you’re studying, statistical knowledge, some programming ability, and most importantly, the ability to translate your results for non-analysts. At rstudio::conf() in January 2017, Hilary Parker gave a presentation that pinpoints some of the most critical challenges faced by data analysts. In her talk, she notes that “creating an analysis is a hard, error-ridden process that gets ‘yadda-yadda-ed’ away” because we’re reluctant to share our own workflows and/or limit another analyst’s “creativity.” These norms between analyst can not only limit their own professional growth, it inevitably leads to mistakes that go unnoticed because there’s only been one pair of eyes on a project. To address this problem, Parker recommends that we start to think about ourselves as “analysis developers” and borrow some concepts from programmers and engineers. Errors will happen. Parker notes that we can learn from operations engineers, particularly Sidney Dekker’s book, “Understanding Human Error.” The lesson of this book is to not blame a person for their errors and instead to look at the process they used. This helps to make the after-action review conversations less personal and more focused on solving the problem at hand. Reducing error is a big reason to care about developing a healthy, collaborative culture among “analysis developers,” but there are many other benefits to improving how these folks work. It can help improve the quality and depth of analysis as they start to learn from one another. A more collaborative environment can also improve the speed of analysis as analysis development moves from an ad-hoc approach to one that follows a more standardized routine. This will also help to improve institutional knowledge of the analysis development process, making it easier to integrate new staff and maintain stability after a personnel transition. Education agencies could develop more accurate, high-quality, and reproducible analyses, but it order to do so, they need to deliberately build a strong collaborative culture among their analysis developers. "],
["team-structure.html", "Chapter 3 Team structure 3.1 Your primary collaborator 3.2 E pluribus unum", " Chapter 3 Team structure 3.1 Your primary collaborator No man is an island, and analysis developers are no different. Even if you are working as the lone analysis developer in your agency, it doesn’t mean you can neglect the structures a team needs to be successful. As Hadley Wickham notes in his {Expressing yourself with R](https://youtu.be/1POb5fx_m3I?t=34m12s) talk: “Every project you work on is fundamentally collaborative. Even if you’re not working with any other person, you are always working with future you. And you really don’t want to be in a situation where future you has no idea what past you was thinking, because past you will not respond to any emails.” The rest of this book assumes that you have embraced this idea. No matter the size of your team, from 1 to n, it is critical that you think about, test, and improve the systems you use to collaborate with others. 3.2 E pluribus unum Teams of analysis developers don’t form on their own - it takes leadership to build, grow, and maintain. The work can be challenging, as many prospective team members may come from differnet backgrounds, use different software packages, or tackle analysis via ideosyncratic (at sometimes inscrutable) methods. Yet at the same time, the heterogenatiy of your team is also an asset. The differing perspectives and strengths of your team’s members will allow you to survey problems from different angles and help mitigate the danger of groupthink. The leader of a analysis development team needs to do more than run meetings and assign work. They may help provide support on implementing particualr methodologies, perform final code reviews, and approve analysis before it is shipped outside the team. But the most crticial job they have is to ensure a healthy team culture. Building a strong team culture is hard. It relies on mutual trust, humility, and honesty - virtues that aren’t always easy to embody. But it can be done. As you start to think intentionally about your team’s culture, this sequence is a helpful staring point: Understand what your team culture is like right now. Define what direction your culture needs to move. Identify the behaviors/routines your team will implement to get there. Implement the selected behaviors/routines. Repeat. This process is a variant of the Observe-Orient-Decide-Act (OODA) loop a strategic decision-making processed developed bya a fighter pilot. While building a team of analysis developer’s isn’t quite as intesnse as a dogfight, this process of intentional observation, decision-making, and action is an extremely helpful way to start improving your team’s culture at any stage of development. Developing a strong team culture is not a goal - it’s a continual process. This variation of the OODA loop supports thougthful observation, adaptation, and action. If your team is just starting to meet and is very heterogeneous, you won’t be able to get everybody working on the same software and using the same processes overnight. It will require intentional, incremental, and iterative change over time. "],
["tools-of-the-trade.html", "Chapter 4 Tools of the trade 4.1 Data analysis software 4.2 Version control", " Chapter 4 Tools of the trade Before you start engaging in analysis development work within your agency, you’ll need to make sure you have the right tools to get the job done. There are two software tools every analyst should utilize: a script-based data analysis software platform and a version control system. 4.1 Data analysis software The most commonly used data analysis software is Microsoft Excel. While nearly every analyst cuts their teeth crafting spreadsheets and pivot tables in this popular software, it’s not an ideal platform for professional analysis developers. Excel’s cell-based structure obscures the formulae that drive analysis work, making it hard for others (and often yourself) to understand what’s actually going on “under the hood.” Scripting-based data analysis languages are the cure for the common spreadsheet. They make the entire analysis process transparent by explicitly stating what actions will happen and the order in which they will be executed. This helps to not only clarify your own analytical approach, it also makes it much easier to catch bugs in your analyses. 4.1.1 The case for R There are many software packages that are well-suited for data analysis, but I use and heartily recommend using R as your main platform for data analysis. It is free (a very important feature to analysis developers working in the public/non-profit sectors), open-source, and has a vibrant community of developers and practitioners working to improve the language. One of the best features of the R language is the comprehensive and diverse collection of packages available on CRAN (the Comprehensive R Archive Network). Packages are the way users in the R community share the tools they create - they contain some combination of R code, documentation, and data. Some of the most popular packages allow users to easily perform statistical operations, create plots, and manipulate their data. R users are also able to take advantage of one of the best integrated development environments (IDE’s), RStudio. This freely available software allows users to interact with an R console, write scripts, view plots, and more through a graphical user interface (GUI). RStudio also has built-in functionality to work with some of the most popular version control systems, including Git and GitHub (more on that later). Perhaps the greatest advantage R has over other data analysis software packages is its community. Package development and support is a big part of this, but the R community is also very active in supporting the growth and development of new R users. There are many free ways to get started learning R, from courses on Coursera to online books. If you’re looking for a place to get started, I recommend R for Data Science. 4.2 Version control At some point, we’ve all worked on a project where we’ve saved multiple versions of a file. “Save as…” is a great tool for simple projects when you’re going from “v1” to “v2” to “final_draft,” but we can quickly push on the edges of this approach’s usefulness. If you want to go back to an earlier iteration of your work, it’s hard to know which version you’re looking for or what changed from “v3” to “v4.” If you’re working with multiple people, emailing documents back and forth, it’s amazing how quickly you can lose track of which “v3FINAL” document is the version you want to be looking at right now - is it the one Jane sent yesterday or is the one Johnny sent today? Version control systems help to alleviate these problems. Instead of requiring you to save multiple versions of one file, version control software allows you to have one file, but track all of the changes made since its inception. The most commonly used version control system is Git, which can be paired with the GitHub service to keep a copy of your documents and the changes you’ve made to them in the cloud. As mentioned above, RStudio integrates well with these services. To learn more about getting started with Git, GitHub, and RStudio, check out Happy Git and GitHub for the useR "],
["communication-is-key.html", "Chapter 5 Communication is key 5.1 Meet regularly 5.2 Establish norms", " Chapter 5 Communication is key Building a team of analysis developers starts with a foundation of honest, humble, and frequent communication. Most analysis developers in education agencies start their careers in isolation, left to their own devices to work with the data for a particular program area or set of schools. Breaking out of that isolation to collaborate with others is difficult, but it all starts with developing strong and supportive systems of communication. 5.1 Meet regularly It may sound obvious, but the first step to establishing good communication as a team of analysis developers is to start meeting and talking on a regular basis. As busy as things can get in our agencies, it is worth carving out an hour of your week to get together and talk about your current projects, challenges you’re facing, and successes you’re realizing. If an hour seems like too much, start with a half hour, but start this habit as soon as you can. Meeting regularly with your team of analysis developers has several benefits. It provides your teammates with the opportunity to step back from their day-to-day work and share their perspective. If one person is struggling with a particular part of a project, another teammate may have tackled a similar challenge earlier in the year and be able to share how they were able to overcome it. These serendipitous moments of collaboration and informal professional development are much more likely to occur if you establish a forum for these conversations to occur. More importantly, meeting regularly helps to establish stronger informal relationships between team members. Not every item on the agenda needs to be strictly work-related, you can also take time to share part of your non-office life. This is a form of team-building that is often overlooked, but it shouldn’t be ignored. Even seemingly-mundane small-talk about what you have planned for the weekend can help build trust and rapport between teammates, making the challenge of forming a high-functioning team much less daunting. 5.2 Establish norms As you start to meet regularly with your team, you will also want to take the time to establish and model healthy norms to support open and honest communication. Sharing your work can be a nerve-racking proposition, exponentially so if you’re trying a new approach or learning a new software language. Setting expectations on the front-end of those conversations will reduce that tension and lead to more productive feedback. To start, make it clear that any feedback on an analysis project is strictly about the process and not about the person. Hilary Parker covers this topic in a talk she gave at the 2017 rstudio::conf(), Opinionated Analysis Development. She discusses the “blameless postmortem” process used during her time at Etsy, in which any errors were discussed by evaluating the process that led to the error, not the person responsible. Mistakes will happen in our work - an approach to resolving them that focuses on improving process over assigning blame to a person will ultimately lead to more productive and less emotional conversations. These conversations about the process of data analysis should be grounded in a sense of humility. While some may be more comfortable and confident in their expertise, nobody has the perfect answer to every problem. As we become experts, it’s important to remember how it felt to be a novice. Any feedback we provide to others should always be done in a spirit that recognizes we tackle difficult problems and are all learning to get better with each analysis we craft. It is also important that while we provide feedback on processes with a sense of humility, it must also be delivered as honestly as possible. Pointing out errors in a particular analytic approach or offer more optimal workflow is good - that’s how we learn and grow. But we must always take caution to make sure that this honest feedback is always focused on the process and not the person. "],
["establish-systems.html", "Chapter 6 Establish systems 6.1 Common analysis format 6.2 Style guide 6.3 Procedural checklists", " Chapter 6 Establish systems Once your team establishes a strong communication system, it’s time to start building systems that will support effective collaboration. Meeting regularly and establishing norms set the foundation for you to have an open and constructive dialogue about apporaches and processes that can give your team more constistency and standarization in the development of analysis products. This isn’t to say that you should strive to have every analysis developer’s work look identical - if that were the case, you could simply write a script to automate it. Moving your team towards more and not total consistency and standardization means that when yoy have opportunities to provide feedback on work, the barriers to understanding are minimized. Seemingly minor roadblocks to understanding what a script is doing, like its organization or how variables are named, each serve as a cognative tax. Establishing good systems will help you limit the level of cognative taxation required to read a teammates’s code, leaving more capacity to engage in the work of analysis development. 6.1 Common analysis format One of the first tasks your team should tackle is developing a common format for analysis. Developing a common format for analysis can help improve understanding of scripts even if they are coded in different languages. A helpful starting point for this conversation is a diagram found in chapter 2 of R for Data Science: worflow_diagram Our team developed our standard analysis template based on this workflow. We start by first importing all packages and raw data that we will need for the analysis. The second section of our code gets the data in a “tidy” format - variables get converted to the proper type, missing variables are addressed, and tables are reshaped to ensure that each column is a variable and each row is a single observation (more on tidy data can be found in R for Data Science chapter 12.2). Once we have tidy data, we then move on to the heart of our analysis work, which always involves some combination of data transformation, modeling, or visualization. Once all of those steps are completed, we then start to develop how we will communicate the results of our analysis. Here is the exact code we use in our template analysis script, which is available on GitHub: # title of analysis # # date started (yyyy-mm-dd) # lead analysis developer # # notes re: purpose of project # load --------------------------- # load packages # load raw data # clean --------------------------- # prepare data in a tidy format # analyze ------------------------- # transform, model, and/or visualize data # communicate --------------------- # produce objects (tables, charts, etc) for communcating results If all of your team starts analysis projects with this template or one that best suits your needs, it reduces the barriers ahead of each team member understanding what an analysis script is doing. You will be able to quickly isolate potential errors or identify creative apporaches to replicate in other analyses. 6.2 Style guide Code style is a constant topic of debate among software developers. Naming conventions, commenting practices, whitespace, and of course, tabs vs. spaces. There are many pre-defined style guides out there for statistical programming lagnuages. As citizens of the tidyverse, our team adheres to the Tidyverse R Style Guide. That may be the right choice for your team or it might not. The point is that you and your teammates need to make a choce and stick to it. It will make reviewing code much, much easier. 6.3 Procedural checklists Apart from your analysis structure and style, your team should also define the procedure for tasks you’ll do on a routine or semi-routine schedule. Once you’ve defined these procedures, be sure to document them in a series of checklists. Several of [o]ur team’s checklists are available on GitHub](https://github.com/alspur/analysis_dev_templates/tree/master/checklists). Why checklists? If it works for airline pilots and surgons, it can work for analysis developers. Atul Gawande’s book, The Checklist Manifesto, explains the value of checklists to highly skilled workers. Professionals of all varieties - programmers, doctors, teachers, pilots, etc. - perform cognatively demanding tasks on regular basis in high-stakes settings. They apply the skills they’ve honed through training, their understanding of their field, and their general experience to execute complex tasks. But no matter how competent or prepared these professionals are, they still make mistakes. Gawande writes: “In a complex environment, experts are up against two main difficulties. The first is the fallibility of human memory and attention, especially when it comes to mundane, routine matters that are easily overlooked under the strain of more pressing events.” … “A further difficulty, just as insidious, is that people can lull themselves into skipping steps even when they remember them. In complex processes, after all, certain steps don’t always matter. Perhaps the elevator controls on airplanes are usually unlocked and a check is pointless most of the time. Perhaps measuring all four vital signs uncovers a worrisome issue in only one out of fifty patients. “This has never been a problem before,” people say. Until one day it is.” There’s nothing wrong with confidence in your ability to practice your profession, but it does breed a degree hubris that even when seemingly benign, can lead to significant errors. Gwande provides several examples of this in the medical field, where skipping seemingly obvious steps can lead to someone having their right knee opened up even if they’re in for an ACL repair on their left knee. The concept of minimizing mistakes in routine processes is also applicable to analysis development. Each analysis project involves follows the broad format of importing, cleaning, transforming, and reporting data. If small steps along the way aren’t double-checked, a tiny error can lead to significant problems with the results. Gwande stresses that using checklists to minimize error isn’t meant to dumb down the work of professionals. Instead, he argues: “It is common to misconceive how checklists function in complex lines of work. They are not comprehensive how-to guides, whether for building a skyscraper or getting a plane out of trouble. They are quick and simple tools aimed to buttress the skills of expert professionals.” … “You want people to make sure to get the stupid stuff right. Yet you also want to leave room for craft and judgment and the ability to respond to unexpected difficulties that arise along the way” Checklists must strike an important balance. They need to cover enough critical points in a process to minimize the “stupid stuff” that could happen, but they also need the flexibility and brevity to be useful in a real-world setting. Gwande explains the difference between a good checklist and a bad one: “Bad checklists are vague and imprecise. They are too long; they are hard to use; they are impractical. They are made by desk jockeys with no awareness of the situations in which they are to be deployed. They treat the people using the tools as dumb and try to spell out every single step. They turn people’s brains off rather than turn them on. Good checklists, on the other hand, are precise. They are efficient, to the point, and easy to use even in the most difficult situations. They do not try to spell out everything—a checklist cannot fly a plane. Instead, they provide reminders of only the most critical and important steps—the ones that even the highly skilled professionals using them could miss. Good checklists are, above all, practical.” Work with your team to develop good checklists. The most valuable checklists you’ll devleop are the ones you actually end up using. Start indentifying the critical steps in your work, write them down, and iterate your checklists to help your team minimize error and ensure consistent quality. "],
["collaborate-on-analysis-development.html", "Chapter 7 Collaborate on analysis development 7.1 Working together on Github 7.2 Code review", " Chapter 7 Collaborate on analysis development 7.1 Working together on Github 7.2 Code review "],
["identify-pain-points.html", "Chapter 8 Identify pain points 8.1 Figure out common problems 8.2 Has anyone already solved this problem? 8.3 Develop internal solutions", " Chapter 8 Identify pain points 8.1 Figure out common problems 8.2 Has anyone already solved this problem? 8.3 Develop internal solutions "],
["share-beyond-your-walls.html", "Chapter 9 Share beyond your walls", " Chapter 9 Share beyond your walls "],
["conclusion.html", "Chapter 10 Conclusion", " Chapter 10 Conclusion "]
]
